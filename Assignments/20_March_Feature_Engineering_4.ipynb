{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a3118ab",
   "metadata": {},
   "source": [
    "Assignment\n",
    "# Q1. What is data encoding? How is it useful in data science?\n",
    "\n",
    "Data encoding is the process of transforming data from one format to another. This is often done to make data more compatible with machine learning algorithms.\n",
    "\n",
    "There are many different data encoding techniques, but some of the most common include:\n",
    "\n",
    "1. Label encoding: This is the simplest encoding technique. It involves assigning a unique integer to each category in a categorical feature. For example, if the categories are \"red,\" \"green,\" and \"blue,\" then label encoding would assign the integers 0, 1, and 2 to each category, respectively.\n",
    "2. One-hot encoding: This is a more complex encoding technique, but it can be more informative for machine learning algorithms. It involves creating a new binary feature for each category in a categorical feature. For example, if the categories are \"red,\" \"green,\" and \"blue,\" then one-hot encoding would create three new binary features: \"is_red,\" \"is_green,\" and \"is_blue.\" Each feature would be set to 1 if the corresponding category is present and 0 if it is not present.\n",
    "3. Hashing encoding: This is a newer encoding technique that can be used to encode categorical features with a large number of categories. It involves hashing the category values to a smaller number of integers. This can be useful for machine learning algorithms that cannot handle a large number of categories.\n",
    "4. Target Guided Ordinal EncodingÂ¶ It is a technique used to encode categorical variables based on their relationship with the target variable. This encoding technique is useful when we have a categorical variable with a large number of unique categories, and we want to use this variable as a feature in our machine learning model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f63884c",
   "metadata": {},
   "source": [
    "# Q2. What is nominal encoding? Provide an example of how you would use it in a real-world scenario.\n",
    "\n",
    "One hot encoding(OHE), also known as nominal encoding, is a technique used to represent categorical data as numerical data, which is more suitable for machine learning algorithms. In this technique, each category is represented as a binary vector where each bit corresponds to a unique category. For example, if we have a categorical variable \"color\" with three possible values (red, green, blue), we can represent it using one hot encoding as follows:\n",
    "\n",
    "1. Red: [1, 0, 0]\n",
    "2. Green: [0, 1, 0]\n",
    "3. Blue: [0, 0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2e7d1d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color</th>\n",
       "      <th>color_blue</th>\n",
       "      <th>color_green</th>\n",
       "      <th>color_red</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>red</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blue</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>green</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>green</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>red</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>blue</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   color  color_blue  color_green  color_red\n",
       "0    red         0.0          0.0        1.0\n",
       "1   blue         1.0          0.0        0.0\n",
       "2  green         0.0          1.0        0.0\n",
       "3  green         0.0          1.0        0.0\n",
       "4    red         0.0          0.0        1.0\n",
       "5   blue         1.0          0.0        0.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pandas as pd\n",
    "\n",
    "#creating simple dataframe\n",
    "df = pd.DataFrame({\n",
    "    'color':['red', 'blue', 'green', 'green', 'red', 'blue']\n",
    "})\n",
    "df.head()\n",
    "\n",
    "#creating instance of OHE\n",
    "ohe_obj = OneHotEncoder()\n",
    "encoded_array = ohe_obj.fit_transform(df[['color']]).toarray()\n",
    "\n",
    "#creating dataframe\n",
    "encoded_df = pd.DataFrame(encoded_array,columns=ohe_obj.get_feature_names_out())\n",
    "encoded_df.head()\n",
    "\n",
    "#concatinating to main df\n",
    "pd.concat([df,encoded_df],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f939c5b5",
   "metadata": {},
   "source": [
    "# Q3. In what situations is nominal encoding preferred over one-hot encoding? Provide a practical example.\n",
    "\n",
    "Nominal encoding is preferred over one-hot encoding in situations where the order of the categories does not matter. For example, if you have a categorical feature that represents the color of a car, such as \"red,\" \"green,\" and \"blue,\" then nominal encoding would be the preferred encoding technique. This is because the order of the colors does not matter.\n",
    "\n",
    "One-hot encoding, on the other hand, is preferred in situations where the order of the categories does matter. For example, if you have a categorical feature that represents the day of the week, such as \"Monday,\" \"Tuesday,\" \"Wednesday,\" \"Thursday,\" \"Friday,\" \"Saturday,\" and \"Sunday,\" then one-hot encoding would be the preferred encoding technique. This is because the order of the days of the week does matter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5fd7a3",
   "metadata": {},
   "source": [
    "# Q4. Suppose you have a dataset containing categorical data with 5 unique values. Which encoding technique would you use to transform this data into a format suitable for machine learning algorithms? Explain why you made this choice.\n",
    "\n",
    "If I have a dataset containing categorical data with 5 unique values, I would use label encoding to transform this data into a format suitable for machine learning algorithms.\n",
    "\n",
    "Here are the reasons why I would choose label encoding:\n",
    "\n",
    "- Label encoding is a simple and easy to understand encoding technique.\n",
    "- Label encoding is relatively fast to compute.\n",
    "- Label encoding does not create a large number of new features, which can be helpful for machine learning algorithms with limited memory.\n",
    "- Label encoding does not assume any ordering of the categories, which is important if the order of the categories does not matter.\n",
    "\n",
    "In the case of a dataset with 5 unique values, label encoding would simply assign a unique integer to each category. For example, if the categories are \"red,\" \"green,\" \"blue,\" \"yellow,\" and \"purple,\" then label encoding would assign the integers 0, 1, 2, 3, and 4 to each category, respectively.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6de608e",
   "metadata": {},
   "source": [
    "# Q5. In a machine learning project, you have a dataset with 1000 rows and 5 columns. Two of the columns are categorical, and the remaining three columns are numerical. If you were to use nominal encoding to transform the categorical data, how many new columns would be created? Show your calculations.\n",
    "\n",
    "Suppose\n",
    "- the number of unique values in the first categorical column is **\"n1\"**\n",
    "- the number of unique values in the second categorical column is **\"n2\"*\n",
    "\n",
    "So, the total number of new columns created = n1 +n2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d68951",
   "metadata": {},
   "source": [
    "# Q6. You are working with a dataset containing information about different types of animals, including their species, habitat, and diet. Which encoding technique would you use to transform the categorical data into a format suitable for machine learning algorithms? Justify your answer.\n",
    "\n",
    "n the context of your animal dataset containing information about species, habitat, and diet, the most suitable encoding technique would likely be One-Hot Encoding. Here's why:\n",
    "\n",
    "One-Hot Encoding: This technique creates new binary columns for each unique category in the categorical variable. Each binary column represents the presence or absence of a particular category. In your dataset, this is particularly useful when dealing with nominal categorical variables, where there is no inherent order or hierarchy among the categories.\n",
    "\n",
    "Species: Since species names are likely distinct and unordered categories (e.g., lion, tiger, elephant), using one-hot encoding would represent each species as a separate binary column, indicating the presence or absence of that species.\n",
    "\n",
    "Habitat: If the habitat categories are distinct and there's no natural ordering (e.g., forest, ocean, desert), one-hot encoding would be suitable. This would allow the machine learning algorithm to treat each habitat independently without assuming any ordinal relationship between them.\n",
    "\n",
    "Diet: Similarly, if the diet categories are independent and not ordered (e.g., herbivore, carnivore, omnivore), one-hot encoding ensures that the algorithm treats each diet type as a separate feature.\n",
    "\n",
    "One-hot encoding provides clear separation of categorical values, preventing any implied numerical relationships that could lead to misinterpretation by the machine learning algorithm. However, it's important to note that one-hot encoding can lead to high dimensionality if there are many unique categories. This could potentially impact the performance of some algorithms and increase computational complexity. It's a good practice to consider dimensionality reduction techniques if the number of categories is large."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0603040",
   "metadata": {},
   "source": [
    "# Q7.You are working on a project that involves predicting customer churn for a telecommunications company. You have a dataset with 5 features, including the customer's gender, age, contract type, monthly charges, and tenure. Which encoding technique(s) would you use to transform the categorical data into numerical data? Provide a step-by-step explanation of how you would\n",
    "\n",
    "To transform the categorical data in the dataset into numerical data for predicting customer churn, you need to choose appropriate encoding techniques. The categorical features in your dataset are \"gender\" and \"contract type.\" Here's a step-by-step explanation of how you could handle each categorical feature:\n",
    "\n",
    "**Categorical Feature 1: Gender**\n",
    "Since \"gender\" is a binary categorical variable with two possible values (\"male\" and \"female\"), you can use a simple technique called Label Encoding:\n",
    "\n",
    "1. Label Encoding: Assign numerical labels to the categories. For instance, you can encode \"male\" as 0 and \"female\" as 1.\n",
    "Label encoding is suitable for binary categorical variables where there is no inherent order between the categories. However, be cautious when applying label encoding to categorical variables with more than two categories, as the algorithm might incorrectly interpret ordinal relationships that do not actually exist.\n",
    "\n",
    "**Categorical Feature 2: Contract Type**\n",
    "The \"contract type\" is a categorical variable with multiple categories (\"month-to-month,\" \"one year,\" and \"two year\"). To properly encode this, you can use One-Hot Encoding:\n",
    "\n",
    "1. One-Hot Encoding: Create new binary columns for each unique category. Each column represents the presence or absence of that category.\n",
    "\n",
    "- Create a new column \"contract_type_month_to_month\" and set it to 1 for rows with \"month-to-month\" contracts, and 0 otherwise.\n",
    "- Create a new column \"contract_type_one_year\" and set it to 1 for rows with \"one year\" contracts, and 0 otherwise.\n",
    "- Create a new column \"contract_type_two_year\" and set it to 1 for rows with \"two year\" contracts, and 0 otherwise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486a546d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
